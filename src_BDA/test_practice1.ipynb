{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, RobustScaler, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import KFold, RepeatedStratifiedKFold, GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, VotingClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>총구매액</th>\n",
       "      <th>최대구매액</th>\n",
       "      <th>환불금액</th>\n",
       "      <th>주구매상품</th>\n",
       "      <th>주구매지점</th>\n",
       "      <th>내점일수</th>\n",
       "      <th>내점당구매건수</th>\n",
       "      <th>주말방문비율</th>\n",
       "      <th>구매주기</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70900400</td>\n",
       "      <td>22000000</td>\n",
       "      <td>4050000.0</td>\n",
       "      <td>골프</td>\n",
       "      <td>부산본점</td>\n",
       "      <td>13.000</td>\n",
       "      <td>1.461538</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>310533100</td>\n",
       "      <td>38558000</td>\n",
       "      <td>48034700.0</td>\n",
       "      <td>농산물</td>\n",
       "      <td>잠실점</td>\n",
       "      <td>63.875</td>\n",
       "      <td>2.433333</td>\n",
       "      <td>0.369863</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>305264140</td>\n",
       "      <td>14825000</td>\n",
       "      <td>30521000.0</td>\n",
       "      <td>가공식품</td>\n",
       "      <td>본  점</td>\n",
       "      <td>63.875</td>\n",
       "      <td>5.812500</td>\n",
       "      <td>0.083277</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7594080</td>\n",
       "      <td>5225000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>주방용품</td>\n",
       "      <td>부산본점</td>\n",
       "      <td>5.000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1795790</td>\n",
       "      <td>1411200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>수산품</td>\n",
       "      <td>청량리점</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        총구매액     최대구매액        환불금액 주구매상품 주구매지점    내점일수   내점당구매건수    주말방문비율  \\\n",
       "0   70900400  22000000   4050000.0    골프  부산본점  13.000  1.461538  0.789474   \n",
       "1  310533100  38558000  48034700.0   농산물   잠실점  63.875  2.433333  0.369863   \n",
       "2  305264140  14825000  30521000.0  가공식품  본  점  63.875  5.812500  0.083277   \n",
       "3    7594080   5225000         0.0  주방용품  부산본점   5.000  2.000000  0.000000   \n",
       "4    1795790   1411200         0.0   수산품  청량리점   3.000  2.666667  0.125000   \n",
       "\n",
       "   구매주기  \n",
       "0  26.0  \n",
       "1   3.0  \n",
       "2   3.0  \n",
       "3  47.0  \n",
       "4   8.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_path = 'bda_q2/X_train.csv'\n",
    "x_test_path = 'bda_q2/X_test.csv'\n",
    "y_train_path = 'bda_q2/y_train.csv'\n",
    "\n",
    "x_train = pd.read_csv(x_train_path, encoding='cp949')\n",
    "y_train = pd.read_csv(y_train_path, encoding='cp949')\n",
    "x_test = pd.read_csv(x_test_path, encoding='cp949')\n",
    "\n",
    "def MissingColumn(df_):\n",
    "    missing_heads = []\n",
    "    for head in df_.keys():\n",
    "        if df_[head].isnull().sum() != 0:\n",
    "            missing_heads.append(head)\n",
    "    return missing_heads\n",
    "\n",
    "def OutlierColumn(df_):\n",
    "    negative_cols = []\n",
    "    outlier_cols = []\n",
    "    for head in df_.keys():\n",
    "        try:\n",
    "            mini = df_[head].min()\n",
    "            if mini < 0:\n",
    "                negative_cols.append(head)\n",
    "            Q1 = df_[head].quantile(.25)\n",
    "            Q3 = df_[head].quantile(.75)\n",
    "            IQR = Q3-Q1\n",
    "            up_bound = Q3 + IQR*3/2\n",
    "            dw_bound = Q1 - IQR*3/2\n",
    "            count = 0\n",
    "            for value in df_[head]:\n",
    "                if value > up_bound:\n",
    "                    count += 1\n",
    "                elif value < dw_bound:\n",
    "                    count += 1\n",
    "            if count != 0:\n",
    "                outlier_cols.append((head, count))\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return negative_cols, outlier_cols\n",
    "\n",
    "x_train_missing_cols = MissingColumn(x_train)\n",
    "x_test_missing_cols = MissingColumn(x_test)\n",
    "y_train_missing_cols = MissingColumn(y_train)\n",
    "# print(x_train_missing_cols, x_test_missing_cols, y_train_missing_cols)\n",
    "# '환불금액' 결측치 존재\n",
    "\n",
    "x_train_neg_cols, x_train_out_cols = OutlierColumn(x_train)\n",
    "x_test_neg_cols, x_test_out_cols = OutlierColumn(x_test)\n",
    "y_train_neg_cols, y_train_out_cols = OutlierColumn(y_train)\n",
    "# print(x_train_neg_cols)\n",
    "# print(x_train_out_cols)\n",
    "# print(x_test_neg_cols)\n",
    "# print(x_test_out_cols)\n",
    "# print(y_train_neg_cols)\n",
    "# print(y_train_out_cols)\n",
    "# '총구매액', '최대구매액' 음수값 존재\n",
    "# '내점일수', '내점당구매건수', '구매주기' 이상값 수정 필요 / '총구매액', '최대구매액', '환불금액'은 수정 X\n",
    "\n",
    "x_train = x_train.fillna(0)\n",
    "x_test = x_test.fillna(0)\n",
    "\n",
    "for head in x_train_neg_cols:\n",
    "    x_train[head] = x_train[head].abs()\n",
    "    x_test[head] = x_test[head].abs()\n",
    "\n",
    "out_cols = ['내점일수', '내점당구매건수', '구매주기']\n",
    "def TransformOutlier(df_, out_cols):\n",
    "    df__ = df_.copy()\n",
    "    for head in out_cols:\n",
    "        Q1 = df__[head].quantile(.25)\n",
    "        Q3 = df__[head].quantile(.75)\n",
    "        IQR = Q3-Q1\n",
    "        up_bound = Q3+IQR*3/2\n",
    "        dw_bound = Q1-IQR*3/2\n",
    "        df__.loc[(df_[head] > up_bound), head] = up_bound\n",
    "        if dw_bound < 0:\n",
    "            df__.loc[(df_[head] < dw_bound), head] = 0\n",
    "        else:\n",
    "            df__.loc[(df_[head] < dw_bound), head] = dw_bound\n",
    "    return df__\n",
    "x_train = TransformOutlier(x_train, out_cols)\n",
    "x_test = TransformOutlier(x_test, out_cols)\n",
    "\n",
    "x_train_missing_cols = MissingColumn(x_train)\n",
    "x_test_missing_cols = MissingColumn(x_test)\n",
    "y_train_missing_cols = MissingColumn(y_train)\n",
    "# print(x_train_missing_cols, x_test_missing_cols, y_train_missing_cols)\n",
    "# 결측치 제거완료\n",
    "\n",
    "x_train_neg_cols, x_train_out_cols = OutlierColumn(x_train)\n",
    "x_test_neg_cols, x_test_out_cols = OutlierColumn(x_test)\n",
    "y_train_neg_cols, y_train_out_cols = OutlierColumn(y_train)\n",
    "# print(x_train_neg_cols)\n",
    "# print(x_train_out_cols)\n",
    "# print(x_test_neg_cols)\n",
    "# print(x_test_out_cols)\n",
    "# 이상치 제거 완료\n",
    "\n",
    "# print(y_train.gender.value_counts()) # 여자 2184, 남자 1316, 0.624가 여성\n",
    "# x_train.info() # '주구매상품', '주구매지점'\n",
    "# x_test.info()\n",
    "\n",
    "train_input = pd.merge(x_train, y_train)\n",
    "train_input = train_input.drop(['cust_id'], axis=1)\n",
    "x_test = x_test.drop(['cust_id'], axis=1)\n",
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fogbo\\anaconda3\\envs\\first_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fogbo\\anaconda3\\envs\\first_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  name      mean\n",
      "0   LR  0.711430\n",
      "1  SVM  0.707154\n",
      "4   RF  0.700521\n",
      "2   NN  0.688309\n",
      "3  KNN  0.655599\n"
     ]
    }
   ],
   "source": [
    "obj_cols = ['주구매상품', '주구매지점']\n",
    "num_cols = [head for head in train_input.drop(['gender'], axis=1).keys() if head not in obj_cols]\n",
    "\n",
    "# num_transformer = Pipeline(steps=[\n",
    "#     ('scaler', RobustScaler())])\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "obj_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "#obj_transformer = LabelEncoder()\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('obj', obj_transformer, obj_cols),\n",
    "    ('num', num_transformer, num_cols)])\n",
    "\n",
    "seed = 1\n",
    "K_val = 5; num_repeat=1; scoring='f1'#scoring='roc_auc' #scoring='f1'; \n",
    "cv = RepeatedStratifiedKFold(n_splits=K_val, n_repeats= num_repeat, random_state=seed)\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_input.drop(['gender'], axis=1),\n",
    "                                                 train_input['gender'],\n",
    "                                                 test_size = 0.1,\n",
    "                                                 random_state = seed)\n",
    "\n",
    "model_1 = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('LR', LogisticRegression())])\n",
    "\n",
    "model_2 = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('SVM', SVC(probability=True))])\n",
    "\n",
    "model_3 = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('NN', MLPClassifier())])\n",
    "\n",
    "model_4 = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('KNN', KNeighborsClassifier())])\n",
    "\n",
    "model_5 = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('RF', RandomForestClassifier())])\n",
    "\n",
    "models = [('LR', model_1), ('SVM', model_2), ('NN', model_3), ('KNN', model_4), ('RF', model_5)]\n",
    "names, means, stds = [], [], []\n",
    "for name, model in models:\n",
    "    #result = cross_val_score(model, train_x, train_y, cv=cv, scoring=scoring)\n",
    "    model.fit(train_x,train_y)\n",
    "    output = model.predict_proba(val_x)\n",
    "    result = roc_auc_score(val_y, output[:,1])\n",
    "    names.append(name)\n",
    "    means.append(result)\n",
    "    #stds.append(result.std())\n",
    "\n",
    "result_df = df({'name':names, 'mean':means}).sort_values(['mean'], ascending=False)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function f1_score in module sklearn.metrics._classification:\n",
      "\n",
      "f1_score(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')\n",
      "    Compute the F1 score, also known as balanced F-score or F-measure\n",
      "    \n",
      "    The F1 score can be interpreted as a weighted average of the precision and\n",
      "    recall, where an F1 score reaches its best value at 1 and worst score at 0.\n",
      "    The relative contribution of precision and recall to the F1 score are\n",
      "    equal. The formula for the F1 score is::\n",
      "    \n",
      "        F1 = 2 * (precision * recall) / (precision + recall)\n",
      "    \n",
      "    In the multi-class and multi-label case, this is the average of\n",
      "    the F1 score of each class with weighting depending on the ``average``\n",
      "    parameter.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <precision_recall_f_measure_metrics>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    y_true : 1d array-like, or label indicator array / sparse matrix\n",
      "        Ground truth (correct) target values.\n",
      "    \n",
      "    y_pred : 1d array-like, or label indicator array / sparse matrix\n",
      "        Estimated targets as returned by a classifier.\n",
      "    \n",
      "    labels : list, optional\n",
      "        The set of labels to include when ``average != 'binary'``, and their\n",
      "        order if ``average is None``. Labels present in the data can be\n",
      "        excluded, for example to calculate a multiclass average ignoring a\n",
      "        majority negative class, while labels not present in the data will\n",
      "        result in 0 components in a macro average. For multilabel targets,\n",
      "        labels are column indices. By default, all labels in ``y_true`` and\n",
      "        ``y_pred`` are used in sorted order.\n",
      "    \n",
      "        .. versionchanged:: 0.17\n",
      "           parameter *labels* improved for multiclass problem.\n",
      "    \n",
      "    pos_label : str or int, 1 by default\n",
      "        The class to report if ``average='binary'`` and the data is binary.\n",
      "        If the data are multiclass or multilabel, this will be ignored;\n",
      "        setting ``labels=[pos_label]`` and ``average != 'binary'`` will report\n",
      "        scores for that label only.\n",
      "    \n",
      "    average : string, [None, 'binary' (default), 'micro', 'macro', 'samples',                        'weighted']\n",
      "        This parameter is required for multiclass/multilabel targets.\n",
      "        If ``None``, the scores for each class are returned. Otherwise, this\n",
      "        determines the type of averaging performed on the data:\n",
      "    \n",
      "        ``'binary'``:\n",
      "            Only report results for the class specified by ``pos_label``.\n",
      "            This is applicable only if targets (``y_{true,pred}``) are binary.\n",
      "        ``'micro'``:\n",
      "            Calculate metrics globally by counting the total true positives,\n",
      "            false negatives and false positives.\n",
      "        ``'macro'``:\n",
      "            Calculate metrics for each label, and find their unweighted\n",
      "            mean.  This does not take label imbalance into account.\n",
      "        ``'weighted'``:\n",
      "            Calculate metrics for each label, and find their average weighted\n",
      "            by support (the number of true instances for each label). This\n",
      "            alters 'macro' to account for label imbalance; it can result in an\n",
      "            F-score that is not between precision and recall.\n",
      "        ``'samples'``:\n",
      "            Calculate metrics for each instance, and find their average (only\n",
      "            meaningful for multilabel classification where this differs from\n",
      "            :func:`accuracy_score`).\n",
      "    \n",
      "    sample_weight : array-like of shape (n_samples,), default=None\n",
      "        Sample weights.\n",
      "    \n",
      "    zero_division : \"warn\", 0 or 1, default=\"warn\"\n",
      "        Sets the value to return when there is a zero division, i.e. when all\n",
      "        predictions and labels are negative. If set to \"warn\", this acts as 0,\n",
      "        but warnings are also raised.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    f1_score : float or array of float, shape = [n_unique_labels]\n",
      "        F1 score of the positive class in binary classification or weighted\n",
      "        average of the F1 scores of each class for the multiclass task.\n",
      "    \n",
      "    See also\n",
      "    --------\n",
      "    fbeta_score, precision_recall_fscore_support, jaccard_score,\n",
      "    multilabel_confusion_matrix\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] `Wikipedia entry for the F1-score\n",
      "           <https://en.wikipedia.org/wiki/F1_score>`_\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn.metrics import f1_score\n",
      "    >>> y_true = [0, 1, 2, 0, 1, 2]\n",
      "    >>> y_pred = [0, 2, 1, 0, 0, 1]\n",
      "    >>> f1_score(y_true, y_pred, average='macro')\n",
      "    0.26...\n",
      "    >>> f1_score(y_true, y_pred, average='micro')\n",
      "    0.33...\n",
      "    >>> f1_score(y_true, y_pred, average='weighted')\n",
      "    0.26...\n",
      "    >>> f1_score(y_true, y_pred, average=None)\n",
      "    array([0.8, 0. , 0. ])\n",
      "    >>> y_true = [0, 0, 0, 0, 0, 0]\n",
      "    >>> y_pred = [0, 0, 0, 0, 0, 0]\n",
      "    >>> f1_score(y_true, y_pred, zero_division=1)\n",
      "    1.0...\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    When ``true positive + false positive == 0``, precision is undefined;\n",
      "    When ``true positive + false negative == 0``, recall is undefined.\n",
      "    In such cases, by default the metric will be set to 0, as will f-score,\n",
      "    and ``UndefinedMetricWarning`` will be raised. This behavior can be\n",
      "    modified with ``zero_division``.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fogbo\\anaconda3\\envs\\first_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fogbo\\anaconda3\\envs\\first_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fogbo\\anaconda3\\envs\\first_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fogbo\\anaconda3\\envs\\first_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fogbo\\anaconda3\\envs\\first_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  name      mean       std\n",
      "0   LR  0.664772  0.011883\n",
      "4   RF  0.641944  0.014501\n",
      "1  SVM  0.635478  0.019192\n",
      "2   NN  0.611699  0.012421\n",
      "3  KNN  0.590477  0.019312\n"
     ]
    }
   ],
   "source": [
    "obj_cols = ['주구매상품', '주구매지점']\n",
    "num_cols = [head for head in train_input.drop(['gender'], axis=1).keys() if head not in obj_cols]\n",
    "\n",
    "# num_transformer = Pipeline(steps=[\n",
    "#     ('scaler', RobustScaler())])\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "obj_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "#obj_transformer = LabelEncoder()\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('obj', obj_transformer, obj_cols),\n",
    "    ('num', num_transformer, num_cols)])\n",
    "\n",
    "seed = 1\n",
    "K_val = 5; num_repeat=1; scoring='roc_auc' #scoring='f1'; \n",
    "cv = RepeatedStratifiedKFold(n_splits=K_val, n_repeats= num_repeat, random_state=seed)\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_input.drop(['gender'], axis=1),\n",
    "                                                 train_input['gender'],\n",
    "                                                 test_size = 0.1,\n",
    "                                                 random_state = seed)\n",
    "\n",
    "model_1 = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('LR', LogisticRegression())])\n",
    "\n",
    "model_2 = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('SVM', SVC(probability=True))])\n",
    "\n",
    "model_3 = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('NN', MLPClassifier())])\n",
    "\n",
    "model_4 = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('KNN', KNeighborsClassifier())])\n",
    "\n",
    "model_5 = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('RF', RandomForestClassifier())])\n",
    "\n",
    "models = [('LR', model_1), ('SVM', model_2), ('NN', model_3), ('KNN', model_4), ('RF', model_5)]\n",
    "names, means, stds = [], [], []\n",
    "for name, model in models:\n",
    "    result = cross_val_score(model, train_x, train_y, cv=cv, scoring=scoring)\n",
    "    names.append(name)\n",
    "    means.append(result.mean())\n",
    "    stds.append(result.std())\n",
    "\n",
    "result_df = df({'name':names, 'mean':means, 'std':stds}).sort_values(['mean'], ascending=False)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6645164680267793"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('LR', LogisticRegression())])\n",
    "\n",
    "LR_param_grid = {\n",
    "    'LR__C':[1, 10],\n",
    "    'LR__class_weight':['balanced'],\n",
    "    'LR__random_state':[seed],\n",
    "    'LR__solver':['lbfgs', 'liblinear']\n",
    "}\n",
    "\n",
    "LR_grid = GridSearchCV(LR, param_grid=LR_param_grid, scoring=scoring, cv=cv, n_jobs=4, verbose=1)\n",
    "LR_grid.fit(train_x, train_y)\n",
    "LR_best = LR_grid.best_estimator_\n",
    "LR_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:   17.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6475876797764829"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('RF', RandomForestClassifier())])\n",
    "\n",
    "RF_param_grid = {\n",
    "    'RF__n_estimators':[100,300],\n",
    "    'RF__criterion':[\"gini\", \"entropy\"],\n",
    "    'RF__random_state':[seed]}\n",
    "\n",
    "RF_grid = GridSearchCV(RF, param_grid=RF_param_grid, scoring=scoring, cv=cv, n_jobs=4, verbose=1)\n",
    "RF_grid.fit(train_x, train_y)\n",
    "RF_best = RF_grid.best_estimator_\n",
    "RF_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:   55.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6710593571663857"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('SVM', SVC(probability=True))])\n",
    "\n",
    "SVM_param_grid={\n",
    "    'SVM__C':[1, 10],\n",
    "    'SVM__kernel':['linear', 'rbf', 'sigmoid'],\n",
    "    'SVM__gamma':['auto'],\n",
    "    'SVM__class_weight':['balanced'],\n",
    "    'SVM__random_state':[seed]\n",
    "}\n",
    "\n",
    "SVM_grid = GridSearchCV(SVM, param_grid=SVM_param_grid, scoring=scoring, cv=cv, n_jobs=4, verbose=1)\n",
    "SVM_grid.fit(train_x, train_y)\n",
    "SVM_best = SVM_grid.best_estimator_\n",
    "SVM_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.716603322072072\n"
     ]
    }
   ],
   "source": [
    "voting = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('LR_best', LR_best),\n",
    "        ('SVM_best', SVM_best)], voting='soft', n_jobs=4, verbose=1)\n",
    "voting.fit(train_x,train_y)\n",
    "prediction = voting.predict_proba(val_x)\n",
    "print(roc_auc_score(val_y, prediction[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7201928490990991\n"
     ]
    }
   ],
   "source": [
    "voting = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('LR_best', LR_best),\n",
    "        ('RF_best', RF_best)], voting='soft', n_jobs=4, verbose=1)\n",
    "voting.fit(train_x,train_y)\n",
    "prediction = voting.predict_proba(val_x)\n",
    "print(roc_auc_score(val_y, prediction[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3500</td>\n",
       "      <td>0.607919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3501</td>\n",
       "      <td>0.166602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3502</td>\n",
       "      <td>0.210615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3503</td>\n",
       "      <td>0.421947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3504</td>\n",
       "      <td>0.517857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>5977</td>\n",
       "      <td>0.620746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>5978</td>\n",
       "      <td>0.650755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>5979</td>\n",
       "      <td>0.688023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>5980</td>\n",
       "      <td>0.493529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>5981</td>\n",
       "      <td>0.553946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2482 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cust_id    gender\n",
       "0        3500  0.607919\n",
       "1        3501  0.166602\n",
       "2        3502  0.210615\n",
       "3        3503  0.421947\n",
       "4        3504  0.517857\n",
       "...       ...       ...\n",
       "2477     5977  0.620746\n",
       "2478     5978  0.650755\n",
       "2479     5979  0.688023\n",
       "2480     5980  0.493529\n",
       "2481     5981  0.553946\n",
       "\n",
       "[2482 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('LR_best', LR_best),\n",
    "        ('RF_best', RF_best)], voting='soft', n_jobs=4, verbose=1)\n",
    "voting.fit(train_input.drop(['gender'],axis=1),train_input.gender)\n",
    "prediction = voting.predict_proba(x_test)\n",
    "\n",
    "x_test = pd.read_csv(x_test_path, encoding='cp949')\n",
    "y_test = df({'cust_id':x_test['cust_id'], 'gender':prediction[:,1]})\n",
    "# y_test.head()\n",
    "output_path = 'bda_q2/2020311427.csv'\n",
    "y_test.to_csv(output_path, index=False)\n",
    "confirm = pd.read_csv(output_path, encoding='cp949')\n",
    "confirm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6079194 , 0.16660223, 0.21061459, ..., 0.6880231 , 0.49352888,\n",
       "       0.55394634])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[:,1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "first_env",
   "language": "python",
   "name": "first_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
